{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "632bad0e-36ac-4011-9771-81180ab31341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 175.9313\n",
      "Epoch [20/200], Loss: 42.2066\n",
      "Epoch [30/200], Loss: 2.8472\n",
      "Epoch [40/200], Loss: 0.3107\n",
      "Epoch [50/200], Loss: 0.9102\n",
      "Epoch [60/200], Loss: 0.6243\n",
      "Epoch [70/200], Loss: 0.2927\n",
      "Epoch [80/200], Loss: 0.2526\n",
      "Epoch [90/200], Loss: 0.2638\n",
      "Epoch [100/200], Loss: 0.2539\n",
      "Epoch [110/200], Loss: 0.2491\n",
      "Epoch [120/200], Loss: 0.2496\n",
      "Epoch [130/200], Loss: 0.2493\n",
      "Epoch [140/200], Loss: 0.2490\n",
      "Epoch [150/200], Loss: 0.2490\n",
      "Epoch [160/200], Loss: 0.2490\n",
      "Epoch [170/200], Loss: 0.2489\n",
      "Epoch [180/200], Loss: 0.2489\n",
      "Epoch [190/200], Loss: 0.2488\n",
      "Epoch [200/200], Loss: 0.2487\n",
      "Validation Loss: 0.2472\n",
      "          ID  prediction\n",
      "0          0    0.618926\n",
      "1          1    0.625085\n",
      "2          2    0.637764\n",
      "3          3    0.656802\n",
      "4          4    0.616778\n",
      "...      ...         ...\n",
      "28795  28795    0.646096\n",
      "28796  28796    0.635733\n",
      "28797  28797    0.660191\n",
      "28798  28798    0.613554\n",
      "28799  28799    0.614569\n",
      "\n",
      "[28800 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fancyimpute import KNN\n",
    "import re\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Defina o caminho para o arquivo train.csv\n",
    "file_path = r'C:\\Users\\Kkk\\3D Objects\\HCT\\df_imputed.csv'\n",
    "\n",
    "# Leia o arquivo CSV\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Step 1: Prepare the data\n",
    "data = df.drop(columns=['ID'])\n",
    "X = data.drop(columns=['efs', 'efs_time'])\n",
    "y = data['efs']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_val = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Step 2: Define the neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "model = Net(input_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Step 3: Train the model\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_val)\n",
    "    val_loss = criterion(outputs, y_val)\n",
    "    print(f'Validation Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# Step 5: Predict and prepare the submission\n",
    "X_test = torch.tensor(df.drop(columns=['ID', 'efs', 'efs_time']).values, dtype=torch.float32)\n",
    "\n",
    "# Configure the DataLoader for batch processing\n",
    "batch_size = 32\n",
    "test_dataset = TensorDataset(X_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Iterate through batches\n",
    "for batch in test_loader:\n",
    "    x_var = batch[0]\n",
    "    ypred_var = model(x_var).sigmoid()\n",
    "    predictions.append(ypred_var.detach().numpy())\n",
    "\n",
    "# Combine the predictions into a single array\n",
    "predictions = np.concatenate(predictions).reshape(-1)\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission = pd.DataFrame({'ID': df.index[:len(predictions)], 'prediction': predictions})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
